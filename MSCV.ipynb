{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9277a240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cognitiveservices-vision-computervision\n",
      "  Downloading azure_cognitiveservices_vision_computervision-0.9.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting msrest>=0.5.0 (from azure-cognitiveservices-vision-computervision)\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "     ---------------------------------------- 0.0/85.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 85.4/85.4 kB ? eta 0:00:00\n",
      "Collecting azure-common~=1.1 (from azure-cognitiveservices-vision-computervision)\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Collecting azure-core>=1.24.0 (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision)\n",
      "  Obtaining dependency information for azure-core>=1.24.0 from https://files.pythonhosted.org/packages/be/4f/a747b2537fea6302ff3a307b1f9701853e65e215afc1a62fa931d031c57a/azure_core-1.30.0-py3-none-any.whl.metadata\n",
      "  Downloading azure_core-1.30.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2023.11.17)\n",
      "Collecting isodate>=0.6.0 (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision)\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 0.0/41.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.7/41.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.3.1)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.31.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from azure-core>=1.24.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.26.16)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2.2)\n",
      "Downloading azure_core-1.30.0-py3-none-any.whl (193 kB)\n",
      "   ---------------------------------------- 0.0/193.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 193.4/193.4 kB 5.9 MB/s eta 0:00:00\n",
      "Installing collected packages: azure-common, isodate, azure-core, msrest, azure-cognitiveservices-vision-computervision\n",
      "Successfully installed azure-cognitiveservices-vision-computervision-0.9.0 azure-common-1.1.28 azure-core-1.30.0 isodate-0.6.1 msrest-0.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure-cognitiveservices-vision-computervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6e60543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROW\n",
      "Bounding box:  [791.0, 1142.0, 1029.0, 1143.0, 1026.0, 1220.0, 790.0, 1222.0]\n",
      "GOOD\n",
      "Bounding box:  [803.0, 1261.0, 1024.0, 1262.0, 1025.0, 1335.0, 801.0, 1335.0]\n",
      "VIBES\n",
      "Bounding box:  [805.0, 1376.0, 1028.0, 1373.0, 1032.0, 1447.0, 805.0, 1453.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "\n",
    "\n",
    "computervision_client = ComputerVisionClient(\"https://mscv2.cognitiveservices.azure.com/\", CognitiveServicesCredentials(\"bc807603e6cc4788ae4dd0f71a81285c\"))\n",
    "\n",
    "# Get an image with text\n",
    "read_image_url = \"https://images.pexels.com/photos/4577514/pexels-photo-4577514.jpeg\"\n",
    "\n",
    "# Call API with URL and raw response (allows you to get the operation location)\n",
    "read_response = computervision_client.read(read_image_url, \\\n",
    "                language = None, \\\n",
    "                pages = None, \\\n",
    "                raw=True)\n",
    "\n",
    "# Get the operation location (URL with an ID at the end) from the response\n",
    "read_operation_location = read_response.headers[\"Operation-Location\"]\n",
    "# Grab the ID from the URL\n",
    "operation_id = read_operation_location.split(\"/\")[-1]\n",
    "\n",
    "# Call the \"GET\" API and wait for it to retrieve the results \n",
    "while True:\n",
    "    read_result = computervision_client.get_read_result(operation_id)\n",
    "    if read_result.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the detected text, line by line\n",
    "if read_result.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in read_result.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            print(\"Bounding box: \",line.bounding_box)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68984662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description of remote image: \n",
      "'a room full of empty chairs' with confidence 48.10%\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "# Authenticate the client\n",
    "computervision_client = ComputerVisionClient(\"https://mscv2.cognitiveservices.azure.com/\", CognitiveServicesCredentials(\"bc807603e6cc4788ae4dd0f71a81285c\"))\n",
    "\n",
    "# Provide image URL\n",
    "remote_image_url = \"https://images.pexels.com/photos/356065/pexels-photo-356065.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=750&w=1260\"\n",
    "\n",
    "# Call API\n",
    "description_results = computervision_client.describe_image(remote_image_url)\n",
    "\n",
    "# Get the captions (descriptions) from the response, with confidence level\n",
    "print(\"Description of remote image: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32bf9bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags in the remote image: \n",
      "'indoor' with confidence 98.97%\n",
      "'furniture' with confidence 97.78%\n",
      "'conference hall' with confidence 94.61%\n",
      "'hall' with confidence 93.70%\n",
      "'convention center' with confidence 92.29%\n",
      "'convention' with confidence 91.10%\n",
      "'wall' with confidence 84.65%\n",
      "'room' with confidence 79.75%\n",
      "'auditorium' with confidence 79.00%\n",
      "'large' with confidence 69.77%\n",
      "'chair' with confidence 65.97%\n",
      "'ceiling' with confidence 62.57%\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "# Authenticate the client\n",
    "computervision_client = ComputerVisionClient(\"https://mscv2.cognitiveservices.azure.com/\", CognitiveServicesCredentials(\"bc807603e6cc4788ae4dd0f71a81285c\"))\n",
    "\n",
    "# Provide image URL\n",
    "remote_image_url = \"https://images.pexels.com/photos/356065/pexels-photo-356065.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=750&w=1260\"\n",
    "\n",
    "# Call API with remote image\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url)\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe2e284b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories from remote image: \n",
      "'indoor_venue' with confidence 91.41%\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "# Authenticate the client\n",
    "computervision_client = ComputerVisionClient(\"https://mscv2.cognitiveservices.azure.com/\", CognitiveServicesCredentials(\"bc807603e6cc4788ae4dd0f71a81285c\"))\n",
    "\n",
    "# Provide image URL\n",
    "remote_image_url = \"https://images.pexels.com/photos/356065/pexels-photo-356065.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=750&w=1260\"\n",
    "\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [\"categories\"]\n",
    "\n",
    "# Call API with URL and features\n",
    "categorize_results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features)\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(categorize_results_remote.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_results_remote.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0d210a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting objects in remote image:\n",
      "object at location 257, 792, 639, 1096\n",
      "object at location 796, 1048, 831, 1114\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "# Authenticate the client\n",
    "computervision_client = ComputerVisionClient(\"https://mscv2.cognitiveservices.azure.com/\", CognitiveServicesCredentials(\"bc807603e6cc4788ae4dd0f71a81285c\"))\n",
    "\n",
    "# Get URL image with different objects\n",
    "remote_image_url_objects = \"https://images.pexels.com/photos/9497630/pexels-photo-9497630.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=750&w=1260\"\n",
    "\n",
    "# Call API with URL\n",
    "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url_objects)\n",
    "\n",
    "# Print detected objects results with bounding boxes\n",
    "print(\"Detecting objects in remote image:\")\n",
    "if len(detect_objects_results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_remote.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c032aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting brands in remote image: \n",
      "'Starbucks' brand detected with confidence 90.2% at location 409, 610, 236, 468\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "# Authenticate the client\n",
    "computervision_client = ComputerVisionClient(\"https://mscv2.cognitiveservices.azure.com/\", CognitiveServicesCredentials(\"bc807603e6cc4788ae4dd0f71a81285c\"))\n",
    "\n",
    "# Get a URL with a brand logo\n",
    "remote_image_url = \"https://images.pexels.com/photos/1437318/pexels-photo-1437318.jpeg?auto=compress&cs=tinysrgb&dpr=2&w=500\"\n",
    "\n",
    "# Select the visual feature(s) you want\n",
    "remote_image_features = [\"brands\"]\n",
    "\n",
    "# Call API with URL and features\n",
    "detect_brands_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
    "\n",
    "print(\"Detecting brands in remote image: \")\n",
    "if len(detect_brands_results_remote.brands) == 0:\n",
    "    print(\"No brands detected.\")\n",
    "else:\n",
    "    for brand in detect_brands_results_remote.brands:\n",
    "        print(\"'{}' brand detected with confidence {:.1f}% at location {}, {}, {}, {}\".format( \\\n",
    "        brand.name, brand.confidence * 100, brand.rectangle.x, brand.rectangle.x + brand.rectangle.w, \\\n",
    "        brand.rectangle.y, brand.rectangle.y + brand.rectangle.h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f0c39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces in the remote image: \n",
      "'None' of age None at location 294, 702, 512, 920\n",
      "'None' of age None at location 384, 207, 563, 386\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "# Authenticate the client\n",
    "computervision_client = ComputerVisionClient(\"https://mscv2.cognitiveservices.azure.com/\", CognitiveServicesCredentials(\"bc807603e6cc4788ae4dd0f71a81285c\"))\n",
    "\n",
    "# Get an image with faces\n",
    "remote_image_url_faces = \"https://images.pexels.com/photos/1405833/pexels-photo-1405833.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=750&w=1260\"\n",
    "\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [\"faces\"]\n",
    "\n",
    "# Call the API with remote URL and features\n",
    "detect_faces_results_remote = computervision_client.analyze_image(remote_image_url_faces, remote_image_features)\n",
    "\n",
    "# Print the results with gender, age, and bounding box\n",
    "print(\"Faces in the remote image: \")\n",
    "if (len(detect_faces_results_remote.faces) == 0):\n",
    "    print(\"No faces detected.\")\n",
    "else:\n",
    "    for face in detect_faces_results_remote.faces:\n",
    "        print(\"'{}' of age {} at location {}, {}, {}, {}\".format(face.gender, face.age, \\\n",
    "        face.face_rectangle.left, face.face_rectangle.top, \\\n",
    "        face.face_rectangle.left + face.face_rectangle.width, \\\n",
    "        face.face_rectangle.top + face.face_rectangle.height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83c059ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing remote image for adult or racy content ... \n",
      "Is adult content: False with confidence 0.39%\n",
      "Has racy content: False with confidence 0.65%\n",
      "Has gory content: True with confidence 92.52%\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "# Authenticate the client\n",
    "computervision_client = ComputerVisionClient(\"https://mscv2.cognitiveservices.azure.com/\", CognitiveServicesCredentials(\"bc807603e6cc4788ae4dd0f71a81285c\"))\n",
    "\n",
    "# Provide image URL\n",
    "remote_image_url = \"https://image.freepik.com/free-photo/gory-terrified-zombie_1194-51.jpg?1\"\n",
    "\n",
    "# Select the visual feature(s) you want\n",
    "remote_image_features = [\"adult\"]\n",
    "# Call API with URL and features\n",
    "detect_adult_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
    "\n",
    "# Print results with adult/racy score\n",
    "print(\"Analyzing remote image for adult or racy content ... \")\n",
    "print(\"Is adult content: {} with confidence {:.2f}%\".format(detect_adult_results_remote.adult.is_adult_content, detect_adult_results_remote.adult.adult_score * 100))\n",
    "print(\"Has racy content: {} with confidence {:.2f}%\".format(detect_adult_results_remote.adult.is_racy_content, detect_adult_results_remote.adult.racy_score * 100))\n",
    "print(\"Has gory content: {} with confidence {:.2f}%\".format(detect_adult_results_remote.adult.is_gory_content, detect_adult_results_remote.adult.gore_score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4908a0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting color scheme of the remote image: \n",
      "Is black and white: False\n",
      "Accent color: C72304\n",
      "Dominant background color: Yellow\n",
      "Dominant foreground color: White\n",
      "Dominant colors: ['Yellow', 'White']\n"
     ]
    }
   ],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import time\n",
    "# Authenticate the client\n",
    "computervision_client = ComputerVisionClient(\"https://mscv2.cognitiveservices.azure.com/\", CognitiveServicesCredentials(\"bc807603e6cc4788ae4dd0f71a81285c\"))\n",
    "\n",
    "# Provide image URL\n",
    "remote_image_url = \"https://images.pexels.com/photos/1831119/pexels-photo-1831119.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=750&w=1260\"\n",
    "\n",
    "# Select the feature(s) you want\n",
    "remote_image_features = [\"color\"]\n",
    "\n",
    "# Call API with URL and features\n",
    "detect_color_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
    "\n",
    "# Print results of color scheme\n",
    "print(\"Getting color scheme of the remote image: \")\n",
    "print(\"Is black and white: {}\".format(detect_color_results_remote.color.is_bw_img))\n",
    "print(\"Accent color: {}\".format(detect_color_results_remote.color.accent_color))\n",
    "print(\"Dominant background color: {}\".format(detect_color_results_remote.color.dominant_color_background))\n",
    "print(\"Dominant foreground color: {}\".format(detect_color_results_remote.color.dominant_color_foreground))\n",
    "print(\"Dominant colors: {}\".format(detect_color_results_remote.color.dominant_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3972ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b0ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
