{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ac385e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\jeong\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.26.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd7b6fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Obtaining dependency information for keras from https://files.pythonhosted.org/packages/ca/48/643d21747d52fa380f572f76c493779fc5b4bd03605247209d2dd0a6d9a9/keras-3.0.2-py3-none-any.whl.metadata\n",
      "  Downloading keras-3.0.2-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Obtaining dependency information for absl-py from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from keras) (1.24.3)\n",
      "Collecting rich (from keras)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/be/be/1520178fa01eabe014b16e72a952b9f900631142ccd03dc36cf93e30c1ce/rich-13.7.0-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: h5py in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from keras) (3.9.0)\n",
      "Collecting dm-tree (from keras)\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-win_amd64.whl (101 kB)\n",
      "     ---------------------------------------- 0.0/101.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 101.3/101.3 kB 6.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jeong\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Downloading keras-3.0.2-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.4/1.0 MB 12.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 0.8/1.0 MB 10.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "   ---------------------------------------- 0.0/130.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 130.2/130.2 kB 7.5 MB/s eta 0:00:00\n",
      "Downloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "   ---------------------------------------- 0.0/240.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 240.6/240.6 kB 14.4 MB/s eta 0:00:00\n",
      "Installing collected packages: namex, dm-tree, absl-py, rich, keras\n",
      "Successfully installed absl-py-2.0.0 dm-tree-0.1.8 keras-3.0.2 namex-0.0.7 rich-13.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7fdc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jeong\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "C:/Users/jeong/Dataset/Train\\Aerodactyl 0\n",
      "C:/Users/jeong/Dataset/Train\\Bulbasaur 1\n",
      "C:/Users/jeong/Dataset/Train\\Charmander 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:970: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/jeong/Dataset/Train\\Dratini 3\n",
      "C:/Users/jeong/Dataset/Train\\Fearow 4\n",
      "C:/Users/jeong/Dataset/Train\\Meowth 5\n",
      "C:/Users/jeong/Dataset/Train\\Pikachu 6\n",
      "C:/Users/jeong/Dataset/Train\\Psyduck 7\n",
      "C:/Users/jeong/Dataset/Train\\Spearow 8\n",
      "C:/Users/jeong/Dataset/Train\\Squirtle 9\n",
      "WARNING:tensorflow:From C:\\Users\\jeong\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jeong\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizati  (None, 112, 112, 32)      128       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D  (None, 112, 112, 32)      288       \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormali  (None, 112, 112, 32)      128       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormali  (None, 112, 112, 64)      256       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D  (None, 56, 56, 64)        576       \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormali  (None, 56, 56, 64)        256       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D  (None, 56, 56, 128)       1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D  (None, 28, 28, 128)       1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormali  (None, 28, 28, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D  (None, 28, 28, 256)       2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D  (None, 14, 14, 256)       2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormali  (None, 14, 14, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2  (None, 14, 14, 512)       4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2  (None, 14, 14, 512)       4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D  (None, 15, 15, 512)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2  (None, 7, 7, 512)         4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormal  (None, 7, 7, 512)         2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2  (None, 7, 7, 1024)        9216      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3228864 (12.32 MB)\n",
      "Trainable params: 3206976 (12.23 MB)\n",
      "Non-trainable params: 21888 (85.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "import random\n",
    "import keras.utils as ku\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.applications import MobileNet\n",
    "\n",
    "\n",
    "train_path = 'C:/Users/jeong/Dataset/Train'\n",
    "folders = os.listdir(train_path)\n",
    "\n",
    "image_data = []\n",
    "labels = []\n",
    "count = 0\n",
    "\n",
    "for ix in folders:\n",
    "    path = os.path.join(train_path, ix)\n",
    "    # Uncommment the below statement to view the path to the images and their labels\n",
    "    print(path, count)\n",
    "    for im in os.listdir(path):\n",
    "        try:\n",
    "            img = image.load_img(os.path.join(path,im), target_size = (224,224))\n",
    "            img_array = image.img_to_array(img)\n",
    "            image_data.append(img_array)\n",
    "            labels.append(count)\n",
    "        except:\n",
    "            pass\n",
    "    count += 1\n",
    "\n",
    "combined_dataset = list(zip(image_data, labels))\n",
    "random.shuffle(combined_dataset)\n",
    "image_data[:], labels[:] = zip(*combined_dataset)\n",
    "\n",
    "X_train = np.array(image_data)\n",
    "Y_train = np.array(labels)\n",
    "\n",
    "Y_train = ku.to_categorical(Y_train)\n",
    "'''\n",
    "model = ResNet50(include_top = False, weights = 'imagenet', input_shape = (224,224,3))\n",
    "#print(model.summary())\n",
    "'''\n",
    "mobile_net_model = MobileNet(include_top=False, weights='imagenet', input_shape = (224,224,3))\n",
    "mobile_net_model.summary()\n",
    "\n",
    "# The ResNet50 model's output is going to be connected to this classifier.\n",
    "\n",
    "av1 = GlobalAveragePooling2D()(mobile_net_model.output)\n",
    "\n",
    "fc1 = Dense(256, activation = 'relu')(av1)\n",
    "\n",
    "d1 = Dropout(0.5)(fc1)\n",
    "\n",
    "fc2 = Dense(128, activation = 'relu')(d1)\n",
    "\n",
    "d2 = Dropout(0.5)(fc2)\n",
    "\n",
    "fc3 = Dense(64, activation = 'relu')(d2)\n",
    "\n",
    "d3 = Dropout(0.5)(fc3)\n",
    "\n",
    "fc4 = Dense(10, activation = 'softmax')(d3)\n",
    "\n",
    "mobile_net_final_model = Model(inputs = mobile_net_model.input, outputs = fc4)\n",
    "#mobile_net_final_model.summary()\n",
    "\n",
    "# Compile the model\n",
    "adam = Adam(lr = 0.00003)\n",
    "mobile_net_final_model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421fa841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizati  (None, 112, 112, 32)      128       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D  (None, 112, 112, 32)      288       \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormali  (None, 112, 112, 32)      128       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormali  (None, 112, 112, 64)      256       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D  (None, 56, 56, 64)        576       \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormali  (None, 56, 56, 64)        256       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D  (None, 56, 56, 128)       1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormali  (None, 56, 56, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D  (None, 28, 28, 128)       1152      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormali  (None, 28, 28, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D  (None, 28, 28, 256)       2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormali  (None, 28, 28, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D  (None, 14, 14, 256)       2304      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormali  (None, 14, 14, 256)       1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D  (None, 14, 14, 512)       4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormali  (None, 14, 14, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2  (None, 14, 14, 512)       4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2  (None, 14, 14, 512)       4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormal  (None, 14, 14, 512)       2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D  (None, 15, 15, 512)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2  (None, 7, 7, 512)         4608      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormal  (None, 7, 7, 512)         2048      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2  (None, 7, 7, 1024)        9216      \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormal  (None, 7, 7, 1024)        4096      \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 1024)              0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               262400    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3533066 (13.48 MB)\n",
      "Trainable params: 2968650 (11.32 MB)\n",
      "Non-trainable params: 564416 (2.15 MB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for ix in range(50):\n",
    "    mobile_net_final_model.layers[ix].trainable = False\n",
    "print(mobile_net_final_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db8fb272",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\jeong\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jeong\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jeong\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jeong\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 50s 536ms/step - loss: 2.4741 - accuracy: 0.1786 - val_loss: 1.8697 - val_accuracy: 0.3161\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 49s 587ms/step - loss: 1.7218 - accuracy: 0.3951 - val_loss: 1.3521 - val_accuracy: 0.6049\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 47s 561ms/step - loss: 1.3071 - accuracy: 0.5783 - val_loss: 1.1505 - val_accuracy: 0.6626\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 46s 559ms/step - loss: 1.1864 - accuracy: 0.6109 - val_loss: 0.8759 - val_accuracy: 0.7447\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 47s 563ms/step - loss: 0.9971 - accuracy: 0.6824 - val_loss: 2.9680 - val_accuracy: 0.4498\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 49s 594ms/step - loss: 1.1020 - accuracy: 0.6679 - val_loss: 0.8393 - val_accuracy: 0.7751\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 53s 636ms/step - loss: 0.9437 - accuracy: 0.7249 - val_loss: 0.9244 - val_accuracy: 0.7568\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 48s 581ms/step - loss: 0.7609 - accuracy: 0.7751 - val_loss: 0.5496 - val_accuracy: 0.8085\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 56s 676ms/step - loss: 0.7022 - accuracy: 0.7713 - val_loss: 1.5494 - val_accuracy: 0.7356\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 48s 580ms/step - loss: 0.6504 - accuracy: 0.8040 - val_loss: 3.0983 - val_accuracy: 0.5046\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 53s 634ms/step - loss: 0.5701 - accuracy: 0.8359 - val_loss: 1.9010 - val_accuracy: 0.7173\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 59s 716ms/step - loss: 0.7618 - accuracy: 0.7827 - val_loss: 0.6374 - val_accuracy: 0.7994\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 50s 602ms/step - loss: 0.5307 - accuracy: 0.8511 - val_loss: 1.1855 - val_accuracy: 0.7720\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 55s 664ms/step - loss: 0.6500 - accuracy: 0.8321 - val_loss: 3.0367 - val_accuracy: 0.5623\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 57s 686ms/step - loss: 0.4646 - accuracy: 0.8594 - val_loss: 0.9061 - val_accuracy: 0.7629\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 48s 580ms/step - loss: 0.5515 - accuracy: 0.8602 - val_loss: 0.5623 - val_accuracy: 0.8237\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 55s 669ms/step - loss: 0.4952 - accuracy: 0.8457 - val_loss: 0.6304 - val_accuracy: 0.8024\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 58s 696ms/step - loss: 0.4247 - accuracy: 0.8678 - val_loss: 1.1404 - val_accuracy: 0.7903\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 50s 597ms/step - loss: 0.4852 - accuracy: 0.8617 - val_loss: 1.0561 - val_accuracy: 0.7204\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 66s 801ms/step - loss: 0.3810 - accuracy: 0.8716 - val_loss: 0.3737 - val_accuracy: 0.9027\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 66s 790ms/step - loss: 0.3266 - accuracy: 0.8723 - val_loss: 0.4094 - val_accuracy: 0.8693\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 56s 674ms/step - loss: 0.3057 - accuracy: 0.8883 - val_loss: 0.5250 - val_accuracy: 0.8602\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 68s 820ms/step - loss: 0.4471 - accuracy: 0.8571 - val_loss: 2.0792 - val_accuracy: 0.5106\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 73s 873ms/step - loss: 0.6477 - accuracy: 0.8267 - val_loss: 0.5427 - val_accuracy: 0.8328\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 59s 714ms/step - loss: 0.6045 - accuracy: 0.8374 - val_loss: 1.4730 - val_accuracy: 0.6444\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 64s 776ms/step - loss: 0.4059 - accuracy: 0.8799 - val_loss: 0.5421 - val_accuracy: 0.8419\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 63s 753ms/step - loss: 0.4588 - accuracy: 0.8473 - val_loss: 0.8438 - val_accuracy: 0.8024\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 57s 688ms/step - loss: 0.3726 - accuracy: 0.8701 - val_loss: 0.5332 - val_accuracy: 0.8298\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 71s 859ms/step - loss: 0.3449 - accuracy: 0.8822 - val_loss: 0.3601 - val_accuracy: 0.8815\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 55s 657ms/step - loss: 0.2874 - accuracy: 0.8959 - val_loss: 0.3654 - val_accuracy: 0.8906\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 65s 787ms/step - loss: 0.2984 - accuracy: 0.8974 - val_loss: 0.7032 - val_accuracy: 0.8237\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 58s 698ms/step - loss: 0.3497 - accuracy: 0.8845 - val_loss: 0.6138 - val_accuracy: 0.8328\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 52s 630ms/step - loss: 0.2989 - accuracy: 0.8944 - val_loss: 0.5453 - val_accuracy: 0.8541\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 65s 781ms/step - loss: 0.2947 - accuracy: 0.9050 - val_loss: 0.4628 - val_accuracy: 0.8359\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 71s 858ms/step - loss: 0.4092 - accuracy: 0.8868 - val_loss: 0.7997 - val_accuracy: 0.8055\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 52s 626ms/step - loss: 0.2751 - accuracy: 0.8974 - val_loss: 0.3781 - val_accuracy: 0.8693\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 60s 725ms/step - loss: 0.2685 - accuracy: 0.8997 - val_loss: 0.4092 - val_accuracy: 0.8723\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 71s 856ms/step - loss: 0.1894 - accuracy: 0.9088 - val_loss: 0.4506 - val_accuracy: 0.8723\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 54s 649ms/step - loss: 0.2370 - accuracy: 0.9081 - val_loss: 0.5600 - val_accuracy: 0.8450\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 62s 736ms/step - loss: 0.3218 - accuracy: 0.9027 - val_loss: 0.6762 - val_accuracy: 0.8267\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 79s 950ms/step - loss: 0.5216 - accuracy: 0.8640 - val_loss: 0.9481 - val_accuracy: 0.8146\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 63s 753ms/step - loss: 0.2771 - accuracy: 0.9058 - val_loss: 0.4738 - val_accuracy: 0.8541\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 62s 749ms/step - loss: 0.2854 - accuracy: 0.9035 - val_loss: 0.5648 - val_accuracy: 0.8389\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 80s 967ms/step - loss: 0.2251 - accuracy: 0.9058 - val_loss: 0.3754 - val_accuracy: 0.8845\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 57s 677ms/step - loss: 0.2704 - accuracy: 0.8951 - val_loss: 0.6237 - val_accuracy: 0.8389\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 50s 609ms/step - loss: 0.2842 - accuracy: 0.9035 - val_loss: 0.4689 - val_accuracy: 0.8389\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 60s 721ms/step - loss: 0.2644 - accuracy: 0.8997 - val_loss: 0.4904 - val_accuracy: 0.8693\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 72s 874ms/step - loss: 0.2421 - accuracy: 0.9096 - val_loss: 0.5521 - val_accuracy: 0.8511\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 51s 612ms/step - loss: 0.3458 - accuracy: 0.8936 - val_loss: 0.5622 - val_accuracy: 0.8632\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 52s 626ms/step - loss: 0.2004 - accuracy: 0.9172 - val_loss: 0.4797 - val_accuracy: 0.8936\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 66s 799ms/step - loss: 0.2961 - accuracy: 0.8898 - val_loss: 0.7264 - val_accuracy: 0.8754\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 64s 772ms/step - loss: 0.3617 - accuracy: 0.8997 - val_loss: 0.6256 - val_accuracy: 0.8146\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 50s 598ms/step - loss: 0.2691 - accuracy: 0.9050 - val_loss: 0.4352 - val_accuracy: 0.8632\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 59s 715ms/step - loss: 0.2131 - accuracy: 0.9096 - val_loss: 0.3522 - val_accuracy: 0.8815\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 77s 923ms/step - loss: 0.2072 - accuracy: 0.9225 - val_loss: 0.5302 - val_accuracy: 0.8723\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 65s 779ms/step - loss: 0.1599 - accuracy: 0.9354 - val_loss: 0.5220 - val_accuracy: 0.8663\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 66s 804ms/step - loss: 0.1811 - accuracy: 0.9233 - val_loss: 0.5625 - val_accuracy: 0.8663\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 64s 765ms/step - loss: 0.1661 - accuracy: 0.9240 - val_loss: 0.5730 - val_accuracy: 0.8845\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 48s 581ms/step - loss: 0.1407 - accuracy: 0.9369 - val_loss: 0.5094 - val_accuracy: 0.8815\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 54s 658ms/step - loss: 0.1541 - accuracy: 0.9331 - val_loss: 0.5876 - val_accuracy: 0.8815\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 67s 807ms/step - loss: 0.3527 - accuracy: 0.8853 - val_loss: 0.8756 - val_accuracy: 0.7599\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 53s 639ms/step - loss: 0.3878 - accuracy: 0.8913 - val_loss: 1.4906 - val_accuracy: 0.7386\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 49s 587ms/step - loss: 0.2314 - accuracy: 0.8974 - val_loss: 0.5396 - val_accuracy: 0.8511\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 60s 729ms/step - loss: 0.2272 - accuracy: 0.9119 - val_loss: 0.4300 - val_accuracy: 0.8602\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 68s 822ms/step - loss: 0.1961 - accuracy: 0.9111 - val_loss: 0.6273 - val_accuracy: 0.8754\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 53s 636ms/step - loss: 0.3470 - accuracy: 0.8967 - val_loss: 0.9766 - val_accuracy: 0.8237\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 54s 656ms/step - loss: 0.2168 - accuracy: 0.9126 - val_loss: 0.7330 - val_accuracy: 0.8237\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 67s 811ms/step - loss: 0.1980 - accuracy: 0.9187 - val_loss: 0.5267 - val_accuracy: 0.9027\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 55s 663ms/step - loss: 0.1998 - accuracy: 0.9179 - val_loss: 0.5896 - val_accuracy: 0.8723\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 48s 584ms/step - loss: 0.1578 - accuracy: 0.9278 - val_loss: 0.7293 - val_accuracy: 0.8754\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 56s 677ms/step - loss: 0.1427 - accuracy: 0.9210 - val_loss: 0.4597 - val_accuracy: 0.8875\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 67s 808ms/step - loss: 0.1805 - accuracy: 0.9210 - val_loss: 0.4086 - val_accuracy: 0.8784\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 49s 594ms/step - loss: 0.2058 - accuracy: 0.9202 - val_loss: 0.5961 - val_accuracy: 0.8602\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 51s 618ms/step - loss: 0.3497 - accuracy: 0.8959 - val_loss: 0.4441 - val_accuracy: 0.8815\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 63s 759ms/step - loss: 0.2427 - accuracy: 0.9362 - val_loss: 0.6324 - val_accuracy: 0.8723\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 59s 704ms/step - loss: 0.1943 - accuracy: 0.9240 - val_loss: 0.6631 - val_accuracy: 0.8845\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 50s 602ms/step - loss: 0.2011 - accuracy: 0.9134 - val_loss: 0.5951 - val_accuracy: 0.8602\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 61s 733ms/step - loss: 0.2410 - accuracy: 0.9225 - val_loss: 0.6916 - val_accuracy: 0.8663\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 59s 705ms/step - loss: 0.2834 - accuracy: 0.9157 - val_loss: 0.6206 - val_accuracy: 0.8541\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 48s 574ms/step - loss: 0.1383 - accuracy: 0.9438 - val_loss: 0.5397 - val_accuracy: 0.8997\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 54s 653ms/step - loss: 0.1479 - accuracy: 0.9384 - val_loss: 0.6187 - val_accuracy: 0.8936\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 68s 819ms/step - loss: 0.1461 - accuracy: 0.9369 - val_loss: 0.5008 - val_accuracy: 0.9088\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 52s 627ms/step - loss: 0.1227 - accuracy: 0.9476 - val_loss: 0.5485 - val_accuracy: 0.9027\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 51s 616ms/step - loss: 0.1410 - accuracy: 0.9422 - val_loss: 0.4719 - val_accuracy: 0.9149\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 61s 741ms/step - loss: 0.1976 - accuracy: 0.9445 - val_loss: 0.6587 - val_accuracy: 0.8571\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 60s 723ms/step - loss: 0.5470 - accuracy: 0.8670 - val_loss: 1.3319 - val_accuracy: 0.7264\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 49s 585ms/step - loss: 0.2333 - accuracy: 0.9248 - val_loss: 0.5142 - val_accuracy: 0.8936\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 58s 704ms/step - loss: 0.3173 - accuracy: 0.9362 - val_loss: 0.9505 - val_accuracy: 0.7842\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 70s 846ms/step - loss: 0.3983 - accuracy: 0.8853 - val_loss: 0.4976 - val_accuracy: 0.8784\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 52s 622ms/step - loss: 0.1801 - accuracy: 0.9400 - val_loss: 0.4935 - val_accuracy: 0.9088\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 54s 646ms/step - loss: 0.1501 - accuracy: 0.9438 - val_loss: 0.6219 - val_accuracy: 0.9088\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 67s 813ms/step - loss: 0.1873 - accuracy: 0.9506 - val_loss: 0.5028 - val_accuracy: 0.9119\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 61s 737ms/step - loss: 0.1229 - accuracy: 0.9620 - val_loss: 0.5231 - val_accuracy: 0.9149\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 48s 580ms/step - loss: 0.1694 - accuracy: 0.9597 - val_loss: 0.6704 - val_accuracy: 0.8632\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 56s 672ms/step - loss: 0.3031 - accuracy: 0.9415 - val_loss: 0.4908 - val_accuracy: 0.9149\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 66s 796ms/step - loss: 0.2384 - accuracy: 0.9476 - val_loss: 0.6664 - val_accuracy: 0.8602\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 51s 615ms/step - loss: 0.2282 - accuracy: 0.9392 - val_loss: 0.5719 - val_accuracy: 0.8967\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 52s 630ms/step - loss: 0.1492 - accuracy: 0.9552 - val_loss: 0.3449 - val_accuracy: 0.9331\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 64s 778ms/step - loss: 0.1127 - accuracy: 0.9749 - val_loss: 0.4420 - val_accuracy: 0.9271\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 51s 619ms/step - loss: 0.1501 - accuracy: 0.9582 - val_loss: 0.6749 - val_accuracy: 0.8784\n"
     ]
    }
   ],
   "source": [
    "hist = mobile_net_final_model.fit(X_train, Y_train, shuffle = True, batch_size = 16, epochs = 100, validation_split = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4123c975",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "correct\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "wrong\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "wrong\n",
      "accuracy_over_first_100: 31.0 %\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "X_train = np.array(image_data)\n",
    "Y_train = np.array(labels)\n",
    "count=0\n",
    "n=100\n",
    "for i in range(n):\n",
    "    x=X_train[i]\n",
    "    x = np.expand_dims(x,axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    pred = mobile_net_final_model.predict(x)\n",
    "    if np.argmax(pred) == Y_train[i]:\n",
    "        count+=1\n",
    "        print('correct')\n",
    "    else:\n",
    "        print('wrong')\n",
    "    #print('predicted:',np.argmax(pred),'label:',Y_train[i])\n",
    "print('accuracy_over_first_100:',count/n*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2f6cb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "6\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "image_path = 'C:/Users/jeong/Dataset/Train/Pikachu/00000000.jpg'\n",
    "img = image.load_img(image_path,target_size = (224,224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "pred = mobile_net_final_model.predict(x)\n",
    "print(np.argmax(pred))\n",
    "\n",
    "image_path = 'C:/Users/jeong/Dataset/Train/Bulbasaur/00000000.png'\n",
    "img = image.load_img(image_path,target_size = (224,224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "pred = mobile_net_final_model.predict(x)\n",
    "print(np.argmax(pred))\n",
    "\n",
    "image_path = \"C:/Users/jeong/Dataset/Train/Meowth/0a7c888c03b54398b83c353a55df965c.jpg\"\n",
    "img = image.load_img(image_path,target_size = (224,224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "pred = mobile_net_final_model.predict(x)\n",
    "print(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65702214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
